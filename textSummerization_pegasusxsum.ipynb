{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "textSummerization_pegasusxsum.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPEilimHdexim3743HvJAm1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parjanyahk/pegasus-xsum_textSummerization/blob/main/textSummerization_pegasusxsum.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PARJANYA H K** "
      ],
      "metadata": {
        "id": "qR98hEn0k18F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Importing and Installing Necessary Dependencies***"
      ],
      "metadata": {
        "id": "b0ot6yrEUCg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing PyTorch\n",
        "\n",
        "import torch"
      ],
      "metadata": {
        "id": "JOl-7X_DT1iF"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing transformers\n",
        "\n",
        "# pip install transformers"
      ],
      "metadata": {
        "id": "P7QhtUPPUB06"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing sentencepiece because it was a needed dependency to import from transformers\n",
        "\n",
        "# pip install sentencepiece"
      ],
      "metadata": {
        "id": "CHaIKzaFZtQF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Importing and Loading The Model***"
      ],
      "metadata": {
        "id": "6owmpbfHVVW5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Td9sM6j6SpbW"
      },
      "outputs": [],
      "source": [
        "# Importing 2 dependency classes from transformers\n",
        "\n",
        "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
        "\n",
        "# PegasusTokenizer allows us to convert the sentences into a set of tokens (unique number representation for the sentences) which can then be used to pass to the DL model\n",
        "# PegasusForConditionalGeneration class holds the DL model and allows us to use the model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading tokenizer\n",
        "\n",
        "tokenizer = PegasusTokenizer.from_pretrained(\"google/pegasus-xsum\")\n",
        "\n",
        "# from_pretrained is a method"
      ],
      "metadata": {
        "id": "nfthqh1hXK1h"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading model\n",
        "\n",
        "model = PegasusForConditionalGeneration.from_pretrained(\"google/pegasus-xsum\")\n",
        "\n",
        "# from_pretrained is a method"
      ],
      "metadata": {
        "id": "Reo_lhPLaCH9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Performing Abstractive Summarization***\n",
        "\n"
      ],
      "metadata": {
        "id": "gIvE1BPialTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample text taken from wikipedia\n",
        "# https://en.wikipedia.org/wiki/Elon_Musk\n",
        "\n",
        "sample = \"\"\"\n",
        "Elon Reeve Musk is an entrepreneur, investor, and business magnate. He is the founder, CEO, and Chief Engineer at SpaceX; early-stage investor, CEO, and Product Architect of Tesla, Inc.; founder of The Boring Company; and co-founder of Neuralink and OpenAI. With an estimated net worth of around US$270 billion as of March 2022,[4] Musk is the wealthiest person in the world according to both the Bloomberg Billionaires Index and the Forbes real-time billionaires list. Musk was born to a Canadian mother and South African father, and raised in Pretoria, South Africa. He briefly attended the University of Pretoria before moving to Canada at age 17 to avoid conscription. He was enrolled at Queen's University and transferred to the University of Pennsylvania two years later, where he received a bachelor's degree in economics and physics. He moved to California in 1995 to attend Stanford University but decided instead to pursue a business career, co-founding the web software company Zip2 with his brother Kimbal. The startup was acquired by Compaq for $307 million in 1999. The same year, Musk co-founded online bank X.com, which merged with Confinity in 2000 to form PayPal. The company was bought by eBay in 2002 for $1.5 billion.\n",
        "\n",
        "In 2002, Musk founded SpaceX, an aerospace manufacturer and space transport services company, of which he is CEO and Chief Engineer. In 2004, he joined electric vehicle manufacturer Tesla Motors, Inc. (now Tesla, Inc.) as chairman and product architect, becoming its CEO in 2008. In 2006, he helped create SolarCity, a solar energy services company that was later acquired by Tesla and became Tesla Energy. In 2015, he co-founded OpenAI, a nonprofit research company that promotes friendly artificial intelligence. In 2016, he co-founded Neuralink, a neurotechnology company focused on developing brainâ€“computer interfaces, and founded The Boring Company, a tunnel construction company. Musk has proposed the Hyperloop, a high-speed vactrain transportation system.\n",
        "\n",
        "Musk has been criticized for unorthodox and unscientific stances and highly publicized controversial statements. In 2018, he was sued by the US Securities and Exchange Commission (SEC) for falsely tweeting that he had secured funding for a private takeover of Tesla. He settled with the SEC, temporarily stepping down from his chairmanship and agreeing to limitations on his Twitter usage. In 2019, he won a defamation trial brought against him by a British caver who advised in the Tham Luang cave rescue. Musk has also been criticized for spreading misinformation about the COVID-19 pandemic and for his other views on such matters as artificial intelligence, cryptocurrency, and public transport.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "2Ib2wk0Aalk2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating tokens\n",
        "\n",
        "tokens = tokenizer(sample, truncation=True, padding=\"longest\", return_tensors=\"pt\")\n",
        "\n",
        "# Using tokenizer, we take the input parameters and store it in tokens\n",
        "# truncation=True will shorten the text to pass it to the model\n",
        "# padding=\"longest\" will set the padding to longest\n",
        "# return_tensors=\"pt\" returns PyTorch tensors "
      ],
      "metadata": {
        "id": "qQGmHVm1bh_M"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens\n",
        "\n",
        "# The sample text has been converted into tokens shown below whcich has input ID, which are actual tokens and attention mask specifies where our attention is being directed when generating the text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEM7zAxEbzVz",
        "outputId": "6e9ed80e-716b-4644-f9b5-59f06dc0acf7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[32981, 77734, 20248,   117,   142,  8406,   108,  6594,   108,   111,\n",
              "           260, 73518,   107,   285,   117,   109,  4252,   108,  2792,   108,\n",
              "           111,  3670,  9822,   134, 37946,   206,   616,   121, 10085,  6594,\n",
              "           108,  2792,   108,   111,  4711, 18663,   113, 11997,   108,  1238,\n",
              "           107,   206,  4252,   113,   139, 64404,  1555,   206,   111,  1229,\n",
              "           121,  9489,   113, 45077, 15365,   111,  2207, 13901,   107,   441,\n",
              "           142,  3627,  2677,  1092,   113,   279,   787,  4811, 28274,  1722,\n",
              "           130,   113,  1051, 56164,  4101, 60708, 20248,   117,   109, 44106,\n",
              "           465,   115,   109,   278,   992,   112,   302,   109, 15742, 74645,\n",
              "           116,  7186,   111,   109, 15347,   440,   121,  1139, 52931,   467,\n",
              "           107, 20248,   140,  1723,   112,   114,  3066,  1499,   111,   793,\n",
              "          2636,  1802,   108,   111,  2244,   115, 37845,   108,   793,  1922,\n",
              "           107,   285,  9397,  3243,   109,   502,   113, 37845,   269,  1218,\n",
              "           112,  1493,   134,   779,  1689,   112,  1405, 91936,   107,   285,\n",
              "           140,  7992,   134,  3991,   131,   116,   502,   111,  5766,   112,\n",
              "           109,   502,   113,  4900,   228,   231,   678,   108,   241,   178,\n",
              "           915,   114,  9779,   131,   116,  1393,   115,  8965,   111,  8343,\n",
              "           107,   285,  1652,   112,  1310,   115, 10349,   112,  2265, 11285,\n",
              "           502,   155,  1159,  1088,   112,  4462,   114,   260,  1010,   108,\n",
              "          1229,   121, 71141,   109,   712,   680,   301, 13919,   522,   122,\n",
              "           169,  2936,  5377, 17746,   107,   139,  6434,   140,  4540,   141,\n",
              "         46889,   118, 10485,  1954,   604,   115, 14991,   139,   310,   232,\n",
              "           108, 20248,  1229,   121, 19128,   338,  1679,  1346,   107,   363,\n",
              "           108,   162, 16938,   122,  5378, 47710,   115,  3555,   112,   515,\n",
              "          9062,   107,   139,   301,   140,  2020,   141,  8082,   115,  6358,\n",
              "           118, 25348,  1722,   107,   222, 14419, 20248,  3271, 37946,   108,\n",
              "           142, 16902,  2845,   111,   501,  2725,   318,   301,   108,   113,\n",
              "           162,   178,   117,  2792,   111,  3670,  9822,   107,   222, 11802,\n",
              "           178,  2182,  2425,  1143,  2845, 11997, 13570,   108,  1238,   107,\n",
              "           143,  7337, 11997,   108,  1238,   107,   158,   130,  7046,   111,\n",
              "           448,  7590,   108,  1935,   203,  2792,   115,  7561,   222, 10235,\n",
              "           178,  1543,   421,  6823, 11238,   108,   114,  2576,   644,   318,\n",
              "           301,   120,   140,   678,  4540,   141, 11997,   111,  1257, 11997,\n",
              "          3013,   107,   222,  4763,   178,  1229,   121, 19128,  2207, 13901,\n",
              "           108,   114,  6992,   473,   301,   120,  8279,  1615,  4958,  3941,\n",
              "           107,   222,  4415,   178,  1229,   121, 19128, 45077, 15365,   108,\n",
              "           114, 12263, 27925,   301,  1957,   124,  1690,  2037,  1198, 24146,\n",
              "         13146,   108,   111,  3271,   139, 64404,  1555,   108,   114,  8483,\n",
              "          1187,   301,   107, 20248,   148,  2962,   109, 79996,   108,   114,\n",
              "           281,   121,  6386, 37106, 20098,  3037,   327,   107, 20248,   148,\n",
              "           174, 16789,   118, 56145,   111,  1596, 40063, 11669,   116,   111,\n",
              "           987, 48638,  8548,  3986,   107,   222,  3939,   178,   140, 18252,\n",
              "           141,   109,   787, 11928,   111,  4978,  2801,   143, 22737,   158,\n",
              "           118, 32854, 32088,   120,   178,   196,  5696,  2149,   118,   114,\n",
              "           808, 22433,   113, 11997,   107,   285,  5862,   122,   109, 11257,\n",
              "           108, 10241, 10926,   308,   135,   169, 83036,   111, 18341,   112,\n",
              "          6244,   124,   169,  2277,  3616,   107,   222,  6360,   178,   576,\n",
              "           114, 48410,  2498,  1457,   464,   342,   141,   114,  1816,  8665,\n",
              "           551,   170,  5361,   115,   109, 64834, 68672,  8665,  5711,   107,\n",
              "         20248,   148,   163,   174, 16789,   118,  8561, 35597,   160,   109,\n",
              "          4585, 44078, 11545, 41428,   111,   118,   169,   176,  1610,   124,\n",
              "           253,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Summarizing***"
      ],
      "metadata": {
        "id": "TE9fg7--d3fK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summary = model.generate(**tokens)\n",
        "\n",
        "# Unpacking everything in tokens using **tokens"
      ],
      "metadata": {
        "id": "8bFaqXpRd0DB"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "{**tokens}\n",
        "\n",
        "#tokens is of type dictionary, identifyable by { } in the output of tokens above"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkwfcpeOedIJ",
        "outputId": "fa8325e9-7d04-484c-8b68-a23fde9f1a35"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1]]),\n",
              " 'input_ids': tensor([[32981, 77734, 20248,   117,   142,  8406,   108,  6594,   108,   111,\n",
              "            260, 73518,   107,   285,   117,   109,  4252,   108,  2792,   108,\n",
              "            111,  3670,  9822,   134, 37946,   206,   616,   121, 10085,  6594,\n",
              "            108,  2792,   108,   111,  4711, 18663,   113, 11997,   108,  1238,\n",
              "            107,   206,  4252,   113,   139, 64404,  1555,   206,   111,  1229,\n",
              "            121,  9489,   113, 45077, 15365,   111,  2207, 13901,   107,   441,\n",
              "            142,  3627,  2677,  1092,   113,   279,   787,  4811, 28274,  1722,\n",
              "            130,   113,  1051, 56164,  4101, 60708, 20248,   117,   109, 44106,\n",
              "            465,   115,   109,   278,   992,   112,   302,   109, 15742, 74645,\n",
              "            116,  7186,   111,   109, 15347,   440,   121,  1139, 52931,   467,\n",
              "            107, 20248,   140,  1723,   112,   114,  3066,  1499,   111,   793,\n",
              "           2636,  1802,   108,   111,  2244,   115, 37845,   108,   793,  1922,\n",
              "            107,   285,  9397,  3243,   109,   502,   113, 37845,   269,  1218,\n",
              "            112,  1493,   134,   779,  1689,   112,  1405, 91936,   107,   285,\n",
              "            140,  7992,   134,  3991,   131,   116,   502,   111,  5766,   112,\n",
              "            109,   502,   113,  4900,   228,   231,   678,   108,   241,   178,\n",
              "            915,   114,  9779,   131,   116,  1393,   115,  8965,   111,  8343,\n",
              "            107,   285,  1652,   112,  1310,   115, 10349,   112,  2265, 11285,\n",
              "            502,   155,  1159,  1088,   112,  4462,   114,   260,  1010,   108,\n",
              "           1229,   121, 71141,   109,   712,   680,   301, 13919,   522,   122,\n",
              "            169,  2936,  5377, 17746,   107,   139,  6434,   140,  4540,   141,\n",
              "          46889,   118, 10485,  1954,   604,   115, 14991,   139,   310,   232,\n",
              "            108, 20248,  1229,   121, 19128,   338,  1679,  1346,   107,   363,\n",
              "            108,   162, 16938,   122,  5378, 47710,   115,  3555,   112,   515,\n",
              "           9062,   107,   139,   301,   140,  2020,   141,  8082,   115,  6358,\n",
              "            118, 25348,  1722,   107,   222, 14419, 20248,  3271, 37946,   108,\n",
              "            142, 16902,  2845,   111,   501,  2725,   318,   301,   108,   113,\n",
              "            162,   178,   117,  2792,   111,  3670,  9822,   107,   222, 11802,\n",
              "            178,  2182,  2425,  1143,  2845, 11997, 13570,   108,  1238,   107,\n",
              "            143,  7337, 11997,   108,  1238,   107,   158,   130,  7046,   111,\n",
              "            448,  7590,   108,  1935,   203,  2792,   115,  7561,   222, 10235,\n",
              "            178,  1543,   421,  6823, 11238,   108,   114,  2576,   644,   318,\n",
              "            301,   120,   140,   678,  4540,   141, 11997,   111,  1257, 11997,\n",
              "           3013,   107,   222,  4763,   178,  1229,   121, 19128,  2207, 13901,\n",
              "            108,   114,  6992,   473,   301,   120,  8279,  1615,  4958,  3941,\n",
              "            107,   222,  4415,   178,  1229,   121, 19128, 45077, 15365,   108,\n",
              "            114, 12263, 27925,   301,  1957,   124,  1690,  2037,  1198, 24146,\n",
              "          13146,   108,   111,  3271,   139, 64404,  1555,   108,   114,  8483,\n",
              "           1187,   301,   107, 20248,   148,  2962,   109, 79996,   108,   114,\n",
              "            281,   121,  6386, 37106, 20098,  3037,   327,   107, 20248,   148,\n",
              "            174, 16789,   118, 56145,   111,  1596, 40063, 11669,   116,   111,\n",
              "            987, 48638,  8548,  3986,   107,   222,  3939,   178,   140, 18252,\n",
              "            141,   109,   787, 11928,   111,  4978,  2801,   143, 22737,   158,\n",
              "            118, 32854, 32088,   120,   178,   196,  5696,  2149,   118,   114,\n",
              "            808, 22433,   113, 11997,   107,   285,  5862,   122,   109, 11257,\n",
              "            108, 10241, 10926,   308,   135,   169, 83036,   111, 18341,   112,\n",
              "           6244,   124,   169,  2277,  3616,   107,   222,  6360,   178,   576,\n",
              "            114, 48410,  2498,  1457,   464,   342,   141,   114,  1816,  8665,\n",
              "            551,   170,  5361,   115,   109, 64834, 68672,  8665,  5711,   107,\n",
              "          20248,   148,   163,   174, 16789,   118,  8561, 35597,   160,   109,\n",
              "           4585, 44078, 11545, 41428,   111,   118,   169,   176,  1610,   124,\n",
              "            253,     1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Returns output tensors (output tokens)\n",
        "# We passed some tensors as input\n",
        "\n",
        "summary\n",
        "\n",
        "# Decoding this will get us the summarizerd text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYDrW--tgCtY",
        "outputId": "46a88197-4de3-4aaf-f5bc-620ce0b40831"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[    0, 32981, 20248,   117,   156,   113,   109,   278,   131,   116,\n",
              "         21315,   200,   107,     1]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Decoding***"
      ],
      "metadata": {
        "id": "pJ4OBsMHhJhe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Decoding summary\n",
        "\n",
        "tokenizer.decode(summary[0])\n",
        "\n",
        "# We can decode using tokenizer\n",
        "# We use [0] to get the first result since the output tokens is nested, meaning it has [[ ]]. We just need the first instance here"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "zea4anp4g-N4",
        "outputId": "46804a74-e21f-479f-f7f0-d0bfd487e14f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Elon Musk is one of the world's richest people.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we go back to Elon's Wikipedia page, and search for the decoded string, we don't find a match.\n",
        "Hence the name Abstractive Summarization."
      ],
      "metadata": {
        "id": "Z-LDHjjvi9qG"
      }
    }
  ]
}